{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " Logically ML Intern whole dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OrPiIX2Qg20",
        "outputId": "cf2f1298-8d9d-420d-edb9-e52f171b80be"
      },
      "source": [
        "import csv                               # csv reader\n",
        "import pandas as pd\n",
        "import re                                       # regular expressions\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "\n",
        "# To do preprocessing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score # to report on precision and recall\n",
        "import numpy as np # To compute the average results\n",
        "\n",
        "from random import shuffle # To shuffle the dataset\n",
        "\n",
        "\n",
        "# To use feature selection in the Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCJ2m5GQW4ML",
        "outputId": "7298b4a4-95f9-4454-dc21-7ad342ebae31"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvsuxM-XXIa1"
      },
      "source": [
        "path_of_file = '/content/drive/MyDrive/Colab Notebooks/Logically.ai/complaints.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPQvB1bBWcGv"
      },
      "source": [
        "columns = [\"Complaint ID\", \"Company\", \"Issue\", \"Consumer complaint narrative\", \"Sub-product\", \"Product\"]\n",
        "df = pd.read_csv(path_of_file, usecols= columns)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "lT55mjMKbPpS",
        "outputId": "81a46e51-47d3-495e-91c5-a301cc1cd623"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Sub-product</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Consumer complaint narrative</th>\n",
              "      <th>Company</th>\n",
              "      <th>Complaint ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
              "      <td>3274605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vehicle loan or lease</td>\n",
              "      <td>Loan</td>\n",
              "      <td>Struggling to pay your loan</td>\n",
              "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
              "      <td>ALLY FINANCIAL INC.</td>\n",
              "      <td>3425257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
              "      <td>3198225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Fees or interest</td>\n",
              "      <td>I have 2 Capital One credit cards and My wife ...</td>\n",
              "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
              "      <td>3202016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EQUIFAX, INC.</td>\n",
              "      <td>3206138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Product  ... Complaint ID\n",
              "0  Credit reporting, credit repair services, or o...  ...      3274605\n",
              "1                              Vehicle loan or lease  ...      3425257\n",
              "2  Credit reporting, credit repair services, or o...  ...      3198225\n",
              "3                        Credit card or prepaid card  ...      3202016\n",
              "4  Credit reporting, credit repair services, or o...  ...      3206138\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qYawr8FVJbQ"
      },
      "source": [
        "## check for Null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGhEqQNsjY0J",
        "outputId": "d2979043-c6d7-4373-a8eb-080f6ac9c545"
      },
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdU8OzCmwcBS",
        "outputId": "0e9f5afb-0102-4b35-eb5b-09d3efe4fd08"
      },
      "source": [
        "nan_values = df.isna()\n",
        "nan_columns = nan_values.any()\n",
        "columns_with_nan = df.columns[nan_columns].tolist()\n",
        "print(columns_with_nan)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sub-product', 'Consumer complaint narrative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0ejmLPIVPIe"
      },
      "source": [
        "## here because its a string data so it is filled by empty string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFdcA3brwkf3",
        "outputId": "d0b697a5-26cd-414f-eb4a-26440e37045f"
      },
      "source": [
        "df.fillna('', inplace=True)\n",
        "df.isnull().values.any()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PARhw5NGVXRu"
      },
      "source": [
        "## Checking class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58SyQZvJY-F5",
        "outputId": "c9a15afd-86ba-4d03-c439-273e53d9af01"
      },
      "source": [
        "df['Product'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Credit reporting, credit repair services, or other personal consumer reports    837147\n",
              "Debt collection                                                                 382216\n",
              "Mortgage                                                                        337857\n",
              "Credit reporting                                                                140432\n",
              "Credit card or prepaid card                                                     122003\n",
              "Checking or savings account                                                     101178\n",
              "Credit card                                                                      89190\n",
              "Bank account or service                                                          86206\n",
              "Student loan                                                                     63174\n",
              "Money transfer, virtual currency, or money service                               32982\n",
              "Consumer Loan                                                                    31602\n",
              "Vehicle loan or lease                                                            27682\n",
              "Payday loan, title loan, or personal loan                                        18867\n",
              "Payday loan                                                                       5543\n",
              "Money transfers                                                                   5354\n",
              "Prepaid card                                                                      3819\n",
              "Other financial service                                                           1058\n",
              "Virtual currency                                                                    18\n",
              "Name: Product, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2zsM0_cGUxR"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['Product'] = le.fit_transform(df['Product'])\n",
        "# print(le.inverse_transform(1))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "_AhlvTZtIdke",
        "outputId": "90dbf27f-89d6-4522-8098-a0086b169a73"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Sub-product</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Consumer complaint narrative</th>\n",
              "      <th>Company</th>\n",
              "      <th>Complaint ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td></td>\n",
              "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
              "      <td>3274605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>Loan</td>\n",
              "      <td>Struggling to pay your loan</td>\n",
              "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
              "      <td>ALLY FINANCIAL INC.</td>\n",
              "      <td>3425257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td></td>\n",
              "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
              "      <td>3198225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>General-purpose credit card or charge card</td>\n",
              "      <td>Fees or interest</td>\n",
              "      <td>I have 2 Capital One credit cards and My wife ...</td>\n",
              "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
              "      <td>3202016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td></td>\n",
              "      <td>EQUIFAX, INC.</td>\n",
              "      <td>3206138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Product  ... Complaint ID\n",
              "0        6  ...      3274605\n",
              "1       16  ...      3425257\n",
              "2        6  ...      3198225\n",
              "3        4  ...      3202016\n",
              "4        6  ...      3206138\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BreSNJPViEb"
      },
      "source": [
        "## method for Loading the data and splitting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcrmp-OHw4sv"
      },
      "source": [
        "def loadData(dataframe):\n",
        "  for index, row in dataframe.iterrows():\n",
        "    (Id, company, issue, complaint_narative, sub_product, product) = parseReviewImproved(row)\n",
        "    rawData.append((Id, company, issue, complaint_narative, sub_product, product))\n",
        "\n",
        "\n",
        "def parseReviewImproved(reviewLine):\n",
        "    Id = int(reviewLine['Complaint ID'])\n",
        "    company = reviewLine['Company']\n",
        "    issue = reviewLine['Issue']\n",
        "    # sub_issue = reviewLine['Sub-issue']\n",
        "    complaint_narative = reviewLine['Consumer complaint narrative']\n",
        "    sub_product = reviewLine['Sub-product']\n",
        "    product = reviewLine['Product']\n",
        "    return (Id, company, issue, complaint_narative, sub_product, product)\n",
        "\n",
        "def splitData(percentage):\n",
        "    dataSamples = len(rawData)\n",
        "    halfOfData = int(len(rawData)/2)\n",
        "    trainingSamples = int((percentage*dataSamples)/2)\n",
        "    for (_, company, issue, complaint_narative, sub_product, product) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "        trainData.append((toFeatureVector(company, sub_product, preProcess(issue), preProcess(complaint_narative)),product))\n",
        "    for (_, company, issue, complaint_narative, sub_product, product) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "        testData.append((toFeatureVector(company, sub_product, preProcess(issue), preProcess(complaint_narative)),product))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tzKdMq0Vm2A"
      },
      "source": [
        "## converting tokens to feature vectore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmuz1aLeA9D6"
      },
      "source": [
        "featureDict = {} # the global feature dictionary\n",
        "\n",
        "def toFeatureVector(company, sub_product, issue_tokens, complaint_tokens):\n",
        "\n",
        "    # return a dictionary 'featureVect' where the keys are the tokens in 'words' and the values are the number of occurrences of the tokens\n",
        "    # start by using binary values only:\n",
        "    # baseDict = {}\n",
        "    featureVec = {}\n",
        "\n",
        "    for w in issue_tokens:\n",
        "      try:\n",
        "          featureVec[w] += 1.0/len(issue_tokens)\n",
        "      except KeyError:\n",
        "          featureVec[w] = 1.0/len(issue_tokens)\n",
        "      try:\n",
        "          featureDict[w] += 1.0/len(issue_tokens)\n",
        "      except KeyError:\n",
        "          featureDict[w] = 1.0/len(issue_tokens)\n",
        "\n",
        "        \n",
        "    for w in complaint_tokens:\n",
        "      try:\n",
        "          featureVec[w] += 1.0/len(complaint_tokens)\n",
        "      except KeyError:\n",
        "          featureVec[w] = 1.0/len(complaint_tokens)\n",
        "      try:\n",
        "          featureDict[w] += 1.0/len(complaint_tokens)\n",
        "      except KeyError:\n",
        "          featureDict[w] = 1.0/len(complaint_tokens)\n",
        "\n",
        "    \n",
        "    featureVec['COMPANY:'+str(company).lower()] = 1.0 # 0.5\n",
        "    featureVec['SUB:'+str(sub_product).lower()] = 1.0 #0.3\n",
        "\n",
        "    try:\n",
        "        featureDict['COMPANY:'+str(company)] += 1.0\n",
        "    except KeyError:\n",
        "        featureDict['COMPANY:'+str(company)] = 1.0\n",
        "\n",
        "    try:\n",
        "        featureDict['SUB:'+str(sub_product)] += 1.0\n",
        "    except KeyError:\n",
        "        featureDict['SUB:'+str(sub_product)] = 1.0\n",
        "\n",
        "    \n",
        "    return featureVec"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJSAr97IVpAs"
      },
      "source": [
        "## Preprocessing the Data and the complaints and making it simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TFqVmEy_xd7"
      },
      "source": [
        "def preProcess(text):\n",
        "    # should return a list of tokens\n",
        "    \n",
        "    # word tokenisation, including punctuation removal\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    \n",
        "    # lowercasing\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "\n",
        "    # stopword removal- benefits are it removes rare words, though bad for bigram relations\n",
        "    if True:\n",
        "        stop = set(stopwords.words('english'))\n",
        "        tokens = [t for t in tokens if t not in stop]\n",
        "    \n",
        "    # lemmatisation\n",
        "    if True:\n",
        "        lemmatiser = WordNetLemmatizer()\n",
        "        tokens = [lemmatiser.lemmatize(t) for t in tokens]\n",
        "        \n",
        "    # stemming- works well with stop word remove\n",
        "    if False:\n",
        "        p_stemmer = PorterStemmer()\n",
        "        tok = []\n",
        "        for t in tokens:\n",
        "            tok.append(p_stemmer.stem(t))\n",
        "        tokens = tok\n",
        "        \n",
        "    tokens = [t for t in tokens if t] # ensure no empty space\n",
        "    \n",
        "    return tokens\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB-eTYOKAZA8",
        "outputId": "805ed558-a383-42af-b1ab-b34d23ce599a"
      },
      "source": [
        "print(preProcess(\"Dear Consumer Financial Protection Bureau Someone had fraudulently created a credit card account with XXXX XXXX and charged over {$5200.00} under my name and this amount has been over due for several months now. I do not bank with XXXX XXXX. \"))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dear', 'consumer', 'financial', 'protection', 'bureau', 'someone', 'fraudulently', 'created', 'credit', 'card', 'account', 'xxxx', 'xxxx', 'charged', '5200', '00', 'name', 'amount', 'due', 'several', 'month', 'bank', 'xxxx', 'xxxx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17HqpJpjw4pl",
        "outputId": "22290395-b9a1-46c1-9f50-10bd509360d1"
      },
      "source": [
        "\n",
        "# loading reviews\n",
        "rawData = [] \n",
        "trainData = [] \n",
        "testData = [] \n",
        "# do the actual stuff\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)))\n",
        "print(\"Preparing the dataset...\")\n",
        "loadData(df)\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)))\n",
        "print(\"Preparing training and test data...\")\n",
        "splitData(0.8)\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 2286328 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "Now 2286328 rawData, 1829062 trainData, 457266 testData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_qjiPaVuwa"
      },
      "source": [
        "# defining out training classifier which is linearSVC with Tfidf Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qF5hoFPU93C"
      },
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "def trainClassifier(trainData):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('tfidf', TfidfTransformer()),('svc', LinearSVC(loss = 'hinge'))])\n",
        "    return SklearnClassifier(pipeline).train(trainData)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuR4IziFV1W0"
      },
      "source": [
        "# method for Predicting the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6_4Pj8RU_vZ"
      },
      "source": [
        "def predictLabels(reviewSamples, classifier):\n",
        "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y8dyMAJV3nI"
      },
      "source": [
        "# method for cross validation to 10 folds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALDaaMHKO51u"
      },
      "source": [
        "def crossValidate(dataset, folds):\n",
        "    shuffle(dataset) # this shuffles the dataset\n",
        "    cv_results = [] # an empty list for storing the results\n",
        "    accuracy = []\n",
        "    foldSize = int(len(dataset)/folds) # foldsize is the size we get dividing the length of dataset by number of folds\n",
        "    \n",
        "    precision = recall = fscore = 0 # variables to store the average result\n",
        "    \n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "        # spitting the dataset in training and validation set\n",
        "        trainingData = dataset[0:i] + dataset[i+foldSize:]\n",
        "        validationData = dataset[i:i+foldSize]\n",
        "        # training the classifier on the split training data\n",
        "        classifier = trainClassifier(trainingData)\n",
        "        # this variable stores the label for final scores\n",
        "        testTrue = [label[1] for label in validationData]\n",
        "        # predicting labels on the validation data\n",
        "        testPred = predictLabels(validationData, classifier)\n",
        "        # finalscores stores the value for precision recall fscore and accuracy\n",
        "        finalScores = precision_recall_fscore_support(testTrue, testPred, average = 'weighted')\n",
        "        accuracy.append(accuracy_score(testTrue, testPred))\n",
        "        cv_results.append(finalScores)\n",
        "        \n",
        "    print('Cross validation done on the dataset and metrics scores are')\n",
        "    \n",
        "    #this for loop block takes the mean of precision, recall, fscore for 10 folds of training and validation data\n",
        "    for scores in cv_results:\n",
        "        precision += scores[0]\n",
        "        recall += scores[1]\n",
        "        fscore += scores[2]\n",
        "        \n",
        "    cv_results = (precision/len(cv_results), recall/len(cv_results), fscore/len(cv_results))\n",
        "    accuracy_result = sum(accuracy)/ len(accuracy) \n",
        "    return cv_results, accuracy_result"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zALU-rHw4ld",
        "outputId": "05517fb0-9d9d-4383-f3e6-63abace4a440"
      },
      "source": [
        "cv_results, accuracy = crossValidate(trainData, 10)\n",
        "print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % cv_results[:3])\n",
        "print(\"accuracy from cross validation is: \", accuracy)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classifier...\n",
            "Cross validation done on the dataset and metrics scores are\n",
            "Precision: 0.996608\n",
            "Recall: 0.996528\n",
            "F Score:0.996497\n",
            "accuracy from cross validation is:  0.9965277743262064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB5g43kzV6CU"
      },
      "source": [
        "## accuracy on the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WHbA61Dw4jm",
        "outputId": "005f2f11-218e-486a-a458-e7ecf39b7540"
      },
      "source": [
        "print(testData[0])   # have a look at the first test data instance\n",
        "classifier = trainClassifier(trainData)  # train the classifier\n",
        "testTrue = [t[1] for t in testData]   # get the ground-truth labels from the data\n",
        "testPred = predictLabels(testData, classifier)  #Â classify the test data to get predicted labels\n",
        "finalScores = precision_recall_fscore_support(testTrue, testPred, average='weighted') # evaluate\n",
        "accuracy = accuracy_score(testTrue, testPred)\n",
        "print(\"Done training!\")\n",
        "print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % finalScores[:3])\n",
        "print(\"accuracy om Test Data is: \", accuracy)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'loan': 0.25, 'modification': 0.25, 'collection': 0.25, 'foreclosure': 0.25, 'COMPANY:ocwen financial corporation': 1.0, 'SUB:other mortgage': 1.0}, 10)\n",
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done training!\n",
            "Precision: 0.995818\n",
            "Recall: 0.994994\n",
            "F Score:0.995180\n",
            "accuracy om Test Data is:  0.9949941609478946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xwm3GmNIH2u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}